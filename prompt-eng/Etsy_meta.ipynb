{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta Prompting\n",
    "\n",
    "Meta prompting is an advanced technique in prompt engineering that emphasizes the structural and syntactical organization of tasks and problems rather than focusing on their specific content. The objective is to create a more abstract, form-driven way of engaging with large language models (LLMs), highlighting patterns and structure over traditional content-focused methods.\n",
    "\n",
    "As outlined by [Zhang et al. (2024)](https://arxiv.org/abs/2311.11482), the defining features of meta prompting include:\n",
    "\n",
    "* Structure-Oriented: Prioritizes the organization and pattern of problems and solutions instead of specific content.\n",
    "* Syntax-Guided: Leverages syntax as a template to shape the expected responses or solutions.\n",
    "* Abstract Frameworks: Uses abstract examples as blueprints, demonstrating the structure of tasks without relying on concrete details.\n",
    "* Domain Versatility: Can be applied across multiple fields, offering structured solutions to diverse problem types.\n",
    "* Categorical Approach: Draws on type theory to organize and categorize components logically, enhancing prompt coherence and precision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running this code on MyBind.org\n",
    "\n",
    "Note: remember that you will need to **adjust CONFIG** with **proper URL and API_KEY**!\n",
    "\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/GenILab-FAU/prompt-eng/HEAD?urlpath=%2Fdoc%2Ftree%2Fprompt-eng%2Fmeta.ipynb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## META PROMPTING\n",
    "##\n",
    "\n",
    "from _pipeline import create_payload, model_req\n",
    "\n",
    "#### (1) Adjust the inbounding Prompt, simulating inbounding requests from users or other systems  \n",
    "MESSAGE = \"Generate a detailed requirement analysis for an Etsy-like marketplace.\"\n",
    "\n",
    "#### (2) Generate a structured prompt for requirement analysis  \n",
    "META_PROMPT = f\"\"\"\n",
    "You are an AI expert in software requirement analysis. Your task is to create a structured prompt that will guide the generation of a complete requirement analysis for an online marketplace similar to Etsy.\n",
    "\n",
    "The structured prompt should ensure:\n",
    "- Functional and non-functional requirements are covered.\n",
    "- The analysis includes user roles (buyers, sellers, admins).\n",
    "- Security and compliance factors (payment processing, fraud detection, data privacy) are considered.\n",
    "- Technical constraints (scalability, API support) are addressed.\n",
    "\n",
    "Generate only the structured prompt.\n",
    "\"\"\"\n",
    "\n",
    "# Step 1: AI generates a structured prompt  \n",
    "payload_meta = create_payload(target=\"ollama\",\n",
    "                              model=\"llama3.2:latest\",  \n",
    "                              prompt=META_PROMPT, \n",
    "                              temperature=0.5, \n",
    "                              num_ctx=150, \n",
    "                              num_predict=200)\n",
    "\n",
    "meta_time, meta_response = model_req(payload=payload_meta)\n",
    "print(\"Generated Structured Prompt:\\n\", meta_response)\n",
    "if meta_time: print(f'Time taken for meta-prompt: {meta_time}s')\n",
    "\n",
    "#### (3) Use the AI-generated structured prompt to get the final requirement analysis  \n",
    "FINAL_PROMPT = meta_response  # Using the AI-generated structured prompt\n",
    "\n",
    "payload_final = create_payload(target=\"ollama\",\n",
    "                               model=\"llama3.2:latest\",  \n",
    "                               prompt=FINAL_PROMPT, \n",
    "                               temperature=0.5, \n",
    "                               num_ctx=200, \n",
    "                               num_predict=300)\n",
    "\n",
    "final_time, final_response = model_req(payload=payload_final)\n",
    "print(\"\\nFinal Requirement Analysis:\\n\", final_response)\n",
    "if final_time: print(f'Time taken for final response: {final_time}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Adjusted Temperature:\n",
    "\n",
    "Reduced randomness so the output stayed more focused and structured.\n",
    "Prevented unnecessary creative variations in the response.\n",
    "\n",
    "Changed from: 1.0 To: 0.5\n",
    "\n",
    "2. Reduced Context Length :\n",
    "The structured prompt phase uses 150 context to keep it concise and efficient.\n",
    "The final increased to 200, allowing more detail without overloading the model.\n",
    "\n",
    "3. Limited Output length:\n",
    "Shorter responses ensure the model stays on track and doesnâ€™t generate excessive, off-topic content.\n",
    "\n",
    "Changed from: 200-300 for Final\n",
    "\n",
    "4. Improved Prompt Structuring\n",
    "Refined meta-prompt to request structured, section-based output.\n",
    "(As in Functional Requirements, Non-Functional Requirements, User Roles..).\n",
    "\n",
    "5. Added Conditional Prompting\n",
    "Ensured the model gave more relevant results depending on the scenario.\n",
    "\n",
    "6. Performance Optimization for CPU\n",
    "Split processing into smaller chunks to avoid overloading the CPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After tuning parameters:\n",
    "\n",
    "Results From:\n",
    "Time taken for meta prompt: 58.339s\n",
    "Time taken for final response: 102.468s\n",
    "\n",
    "To:\n",
    "Time taken for meta prompt: 54.98s\n",
    "Time taken for final response: 82.709s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
